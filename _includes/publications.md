<h2 id="publications" style="margin: 2px 0px -15px;">Selected Publications</h2>

<div class="publications">
<style>
.project-lead {
  display:inline-flex;
  align-items:center;
  gap:4px;
  padding:2px 8px;
  margin-left:2px;
  border-radius:6px;
  background:linear-gradient(90deg,#43a047,#81c784);
  color:#fff;
  font-size:0.75rem;
  font-weight:700;
  line-height:1;
  box-shadow:0 1px 2px rgba(0,0,0,0.15);
}
.project-lead svg {
  width:12px;
  height:12px;
  fill:white;
}
@media (prefers-color-scheme: dark){
  .project-lead {background:linear-gradient(90deg,#66bb6a,#a5d6a7);}
}
</style>
<ol class="bibliography">

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/icra25_visualization.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">ICRA 2025</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://doi.org/10.1109/ICRA55743.2025.11128232">DAP-LED: Learning Degradation-Aware Priors with CLIP for Joint Low-light Enhancement and Deblurring </a></div>
    <div class="author"><strong>Ling Wang</strong>, Chen Wu, Lin Wang*</div>
    <div class="periodical"><em>The IEEE International Conference on Robotics and Automation <strong>(ICRA) </strong>, 2025.</em></div>
    <div class="links">
      <a href="https://doi.org/10.1109/ICRA55743.2025.11128232" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="../assets/video/ICRA25_4264_VI_i.mp4" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Demo</a>
      <a href="https://ras.papercept.net/conferences/conferences/ICRA25/program/ICRA25_ContentListWeb_3.html#thet1_07" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Oral Presentation</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/trans_braindreamer.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">TMM</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/abs/2409.14021">BrainDreamer: Towards Reasoning-Coherent and Controllable Image Reconstruction from EEG Brain Signals via Language Guidance</a></div>
    <div class="author"><strong>Ling Wang<sup>†</sup></strong>, Chen Wu<sup>†</sup>, Lin Wang*</div>
    <div class="periodical"><em>IEEE Transactions on Multimedia <strong>(TMM) </strong>, AQ Oct. 2025.</em></div>
    <div class="links">
      <a href="https://arxiv.org/abs/2409.14021" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/EIT-1M.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">arXiv</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/pdf/2407.01884">EIT-1M: One Million EEG-Image-Text Pairs for Human Visual-textual Recognition and More</a></div>
    <div class="author">Xu Zheng<sup>†</sup>, <strong>Ling Wang<sup>†</sup></strong>, Kanghao Chen, Yuanhuiyi Lyu, Jiazhou Zhou, Lin Wang*</div>
    <div class="periodical"><em>arXiv <strong>(arXiv)</strong>, Jul. 2024.</em></div>
    <div class="links">
      <a href="https://arxiv.org/pdf/2407.01884" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <strong><i style="color:#7b5aa6">arXiv.org</i></strong>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/TelEgo.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">arXiv</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://arxiv.org/pdf/2510.23981">TeleEgo: Benchmarking Egocentric AI Assistants in the Wild</a></div>
    <div class="author">Jiaqi Yan<sup>†</sup>, Ruilong Ren<sup>†</sup>, Jingren Liu<sup>†</sup>, Shuning Xu, Ling Wang, ..., Xiangyu Chen<span class="project-lead">
    <svg viewBox="0 0 24 24"><path d="M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z"/></svg>#Project Lead</span>, Changzhi Sun, Jixiang Luo, Dell Zhang#, Hao Sun, Chi Zhang, Xuelong Li*</div>
    <div class="periodical"><em>arXiv <strong>(arXiv)</strong>, Oct. 2025.</em></div>
    <div class="links">
      <a href="https://arxiv.org/pdf/2510.23981" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/Programmergg/TeleEgo" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/wacv25_d2net.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">WACV 2025</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://doi.org/10.1109/WACV61041.2025.00238">Dropout the High-rate Downsampling: A Novel Design Paradigm for UHD Image Restoration </a></div>
    <div class="author">Chen Wu, <strong>Ling Wang</strong>, Long Peng, Dianjie Lu, Zhuoran Zheng*</div>
    <div class="periodical"><em>The IEEE/CVF Winter Conference on Applications of Computer Vision <strong>(WACV) </strong>, 2025.</em></div>
    <div class="links">
      <a href="https://doi.org/10.1109/WACV61041.2025.00238" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://openaccess.thecvf.com/content/WACV2025/html/Wu_Dropout_the_High-Rate_Downsampling_A_Novel_Design_Paradigm_for_UHD_WACV_2025_paper.html" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Links</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/SPL_AFSMNet.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">IEEE Signal Process. Lett.</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://doi.org/10.1109/LSP.2025.3547669">Adaptive Feature Selection Modulation Network for Efficient Image Super-Resolution </a></div>
    <div class="author">Chen Wu, <strong>Ling Wang</strong>, Xin Su, Zhuoran Zheng*</div>
    <div class="periodical"><em>The IEEE Signal Processing Letters <strong>(SPL)</strong>, 2025.</em></div>
    <div class="links">
      <a href="https://doi.org/10.1109/LSP.2025.3547669" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
      <a href="https://github.com/DavisWANG0/AFSMNet" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">Code</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/AIFlow_method_timeline.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">AI Flow</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://link.springer.com/article/10.1007/s44336-025-00017-w?utm_source=rct_congratemailt">Towards training-free long video understanding: methods, benchmarks, and open challenges </a></div>
    <div class="author">Jingren Liu, Yun Wang, Long Zhang, Yiheng Wang, Shuning Xu, <strong>Ling Wang</strong>, Jiaqi Yan, Dell Zhang & Xiangyu Chen*</div>
    <div class="periodical"><em>AI Flow (Vicinagearth), 2025. </em></div>
    <div class="links">
      <a href="https://link.springer.com/article/10.1007/s44336-025-00017-w?utm_source=rct_congratemailt" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>
  </div>
</div>
</li>

<li>
<div class="pub-row">
  <div class="col-sm-3 abbr" style="position: relative;padding-right: 15px;padding-left: 15px;">
    <img src="assets/img/RS_spvssd.png" class="teaser img-fluid z-depth-1">
    <abbr class="badge">Remote Sens.</abbr>
  </div>

  <div class="col-sm-9" style="position: relative;padding-right: 15px;padding-left: 20px;">
    <div class="title"><a href="https://doi.org/10.3390/rs15010161">SPV-SSD: An Anchor-free 3-D Single-Stage Detector with Supervised-PointRendering and LiDAR Visibility </a></div>
    <div class="author">Lingmei Yin, Wei Tian*, <strong>Ling Wang</strong>, Zhiang Wang, Zhuoping Yu</div>
    <div class="periodical"><em>Remote Sensing, 2023. </em></div>
    <div class="links">
      <a href="https://doi.org/10.3390/rs15010161" class="btn btn-sm z-depth-0" role="button" target="_blank" style="font-size:12px;">PDF</a>
    </div>
  </div>
</div>
</li>

<br>

</ol>
</div>
